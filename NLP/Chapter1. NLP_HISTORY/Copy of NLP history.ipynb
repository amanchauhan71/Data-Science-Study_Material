{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Copy of NLP history.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"oP_ROVMxqwGP"},"source":["  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOCm2NsgqwGO"},"source":["# 1.1. A Brief History of NLP\n","\n","<img src=\".\\Images\\1.png\">\n","\n","![image info](./Images/1.png)\n","\n","In early 1900s, Swiss linguistics Professor named *Ferdinand de Saussure* died, and in the process,he deprived the world for the concept of \"Language as a Science\". In between 1906 and 1911, the professor Saussure offered three courses at the University of Geneva, where professor developed an approach describing languages as \"systems\".Within language, a sound represents the concept - Concept is like shifts meaning as the context changes.\n","\n","He argued that meaning is created inside the language, in the relations and differences between its parts. Professor Saussure proposed \"meaning\" is created within a language's relationships and contrasts. A shared language system makes communication possible. According to the Saussure, Professor see the society as a system of *shared* social norms conditioned for reasonable, \"extended\" thinking, resulting in decisions and actions by the individuals. (The same view we applied in modern computer language)\n","\n","Unfortunately Saussure died in 1913, but after his death, his two colleagues Albert Sechehaye and Charles Bally, recognized his importance of concepts. Just two days after the death of Saussure, they were drinking coffee in Balley's office and wondering how to keep his discoveries from being lost forever. These two took unusual steps of collecting \"his notes for manuscripts\" and his students notes from the courses. By the collection of these things they wrote the [Cours de Linguistique Générale](https://simondlevy.academic.wlu.edu/) , published in 1916. The book is laid the foundation for what has come to be called  the structuralist approach, starting with linguistics and later expanding to the other fields, including computers.\n","\n","In 1950, Alan Turing wrote a paper describing a test for a \"thinking\" machine. Turing stated that if machine could be a part of converstation through the use of teleprinter, and it immitated the human so completely there were no noticable differences, then the machine could be capable of thinking. After a short period in 1952, [the Hodgkin-Huxley model](https://www.swarthmore.edu/NatSci/echeeve1/Ref/HH/HHmain.htm) shows how our brains uses the neuron in forming the electrical network. These events inspired the idea of Artificial intelligence(AI) , Natural Language Processing(NLP), the evolution of computers.\n","\n","## Natural Language Processing (NLP)\n","\n","<img src=\".\\Images\\2.png\">\n","\n","Natural language processing is a subset of Artificial intelligence that helps computers to understand, interpret, and utilize the human languages. NLP allows computers to communicate with peoples using human languages. NLP also provides computers with the ability to read text, hear speech, and try to intrepret it. NLP draws several disciplines, including Computational linguistics and computer science, as this attempts to fill the gap in between human and computer communication.\n","\n","NLP breaks down language into shorter, more basic pieces, called tokens(period, words, etc), and attempts to understand the relationships of tokens. This approach often uses higher-level NLP features, such as:\n","\n","- **Sentiment analysis:** It identifies the general mood, or subjective opinions, which is stored in large amount of texts, It is more useful for opinion mining.\n","\n","- **Contextual Extraction:** Extract structured data from text-base sources.\n","- **Text-to-Speech and Speech-to-text:** It transforms the voice into text and vice a versa.\n","- **Document Summarization:** Automatically creates a synopsis, condensing large amounts of text.\n","- **Machine Translation:** Translates the text or speech of one language into another language.\n","\n","\n","### NLP Initiated and Stopped\n","\n","Noam Chomsky, a Standford professor who published his book, *Syntactic Structures* , in 1957. In this book, he revolutionized previous concept of linguistic concepts, concluding that for a computer to understand the language, sentence structure would have to be changed. To carry this goal, Chomsky created a style of grammar called Phase-Structure Grammar, which methodically translated Natural language sentences into a format that is usable by the computers.\n","\n","In 1958, the programming language LISP(Locator/identifier Sepration Protocol), its still in use today, and it was released by John MacCharthy. In 1964, [ELIZA](https://www.masswerk.at/elizabot/) a \"typewritten\" Comment and response feature was immitating as psychiatrist using refelection techniques was developed.(It is possible just by rearranging sentences and following the simple grammar rules, but there were no understanding on computers). And in a same year, the US national research council(NRC) created the Automatic Language Processing Advisory Committee, or simply we called as ALPAC, in short. The commitee have the task to evaluate the progress of Natural Language Processing reasearch.\n","\n","In just 2years 1966, NRC and ALPAC initiated to stop first AI and NLP, by halting the funding of research on Natural Language processing and machine translation. After twelve years of research,and spending $20 million dollars, machine translation were still more expensive than manual human translation, and there were no any computers that came anywhere near to being able to converse a basic conversation on that time. In 1966, the Artificial intelligence and Natural Language Processing researches were considered dead end by many.\n","\n","### Return of NLP\n","\n","It took nearly about 14years(until 1980) for Natural Language Processing(NLP) and Artificial intelligence(AI) research to recover from the broken expectations created by extreme enthusiasts. This stoppage helps to get a fresh ideas with a new phase for Machine translation, and the earlier concepts of machine learning is abandoned, and these new ideas promoting new research, including expert systems. The mixing of linguistics and statistics which was popular in early NLP research, was replaced with a theme of pure statistics. The 1980 initiated a fundamental reorientation, with some simple approximations replacing the deep analysis, and the evolutional process is more rigorous.\n","\n","Until the 1980, the majority of NLP systems used complex, \"handwritten\" rules.But during the late 1980, a revolution is came out in NLP. This was the result of both the steady increase of computational power and shifted to Machine learning algorithms. While the early of Machine learning algorithms(the decision tree provide a good example) produced systems similar to the old school handwritten rules,then research was mainly focused on the Statistical models. These statistical model are capable in making soft, probablistics decisions. Throughout, the 1980s, IBM was mostly responsible for the development of several successful, complicated statistical model.\n","\n","In 1990s, the popularity of Statistical models for Natural language processes analyses rose dramitically. The pure statistics NLP methods have remarkably valuable in keeping pace with the tremendous flow of online texts. N-grams have became so useful, recognizing and tracking clumps of linguistic data, numerically. In 1997, LSTM Recurrent neural network(RNN) models were introduced that time, and found their niche in 2007 for voice and text processing. Currently neural net models are considered cutting edge of research and development in the NLP's understanding of text and speech generation.\n","\n","### After the year 2000\n","\n","In the year 2001, Yoshio Bengio and his team proposed the first neural \"language\" model using the feed foward network. The feed-foward network that does not use connections to form a cycle. In this type of network, the input data moves only in one direction, from input nodes through any hidden nodes and on to the output nodes.This feed-foward network have no cycle or loops, and is quite different from the RNN(Recurrent neural network).\n","\n","In the year 2011, Apple's Siri became the world's first successful NLP/AI assitants to be useful by general cosumers. In Siri, the Automated Speech recognition module translates the owner's words into digitally interpreted concepts. The Voice-command system matches those commands which we predefined into the model, initiating specific actions. Suppose, if Siri asks, \"Do you want to know your balance?\". So, here you have to understand that Siri wants your response in \"Yes\" or \"No\" and act acordingly.\n","\n","By using Machine learning techniques,the owner's speaking pattern doesn't have to match exactly the pre-defined expressions. The sounds have just to be reasonably close for an NLP system to translate the meaning correctly. By using the feedback loop, NLP engines significantly improve the accuracy of their translations and increase the system's vocabulary. A well trained system understand it better, \"Where can i get a best classes for Data Science?\", \"Where can i get a best mentor for Data Science?\" and provide the appropriate response.\n","\n","The combination of a dialog manger and NLP makes it possible to develop a system capable of holding a conversation, and sounding human-like, with back-and-forth questions, prompts, and answers. Our modern AIs still not pass the Alan Turing's test and currently not sound like real human beings."]},{"cell_type":"markdown","metadata":{"id":"S5eX84BRqwGZ"},"source":["# 1.2. Why learn NLP?\n","\n","<img src=\".\\Images\\3.jpg\">\n","\n","Image taken from - [link](https://www.forbes.com/sites/louiscolumbus/2019/09/25/whats-new-in-gartners-hype-cycle-for-ai-2019/#170b4542547b)\n","\n","You need to see the Gartner's new hype cycle, i start my discussion with this, you can clearly see NLP are on the top of the cycle. Currently, Natural Language Processing(NLP) is one of the rarest skill sets that is required for the industry. After appearance of big data, the main challeges come like we need more people who are good with not just for structured but also with semi or unstructred data. We are generating **petabytes** of Weblogs, tweets, Facebook feeds,chats,e-mails,and reviews in a day. Companies are trying to collect all these different kind of data for better customer targeting and meaningful insights. To process all these unstructured data source we need those people who have the thorough experience in NLP.\n","\n","We are in the age of information, we can't even imagine our life without <u>*Google*</u>. We use basic stuffs with Alexa and Siri and we are habitual with these two.We use spam filters for filtering spam emails.We need spell checker on our Word documents. There were many more examples of real world NLP applications around us.\n","\n","Let me give you some example like they are built with the use of NLP but we are not aware of it:\n","\n","   - Spell Correction(MS Word/any other editor)\n","   - Search engines(Google, Bing, Yahoo)\n","   - Speech engines(like Siri, Google assistant)\n","   - Spam classifiers(All e-mails services)\n","   - News feeds(Google, Yahoo!, and so on)\n","   - Machine Translation(Google translation)\n","   - IBM Watson\n","   \n","Building these above applications we need a required, very specific skill set with a great understanding of language and tools to process the language efficiently. So, it's not just hype that makes NLP one of the most niche areas, but it's the kind of application that can be created using NLP(Natural Language Processing) that makes it one of the most unique skills to have.\n","To achieve one of the above applications and other basic NLP preprocessing, there are many open source tools available. Some of them which are made by organizations to build their own NLP applications, while some of the organizations have open-sourced. Here are the small list of NLP tools are available:\n","   \n","   - GATE\n","   - Mallet\n","   - Open NLP\n","   - UIMA\n","   - Standford toolkit\n","   - Gensim\n","   - **NLTK(Natural Language Tool kit)**\n","   \n","Most of the tools are written in Java and have similar functionalities.And Some of them are robust and have a different variety of NLP tools are avaialable. However, when it comes to ease to use and explaination of the concepts, NLTK scores really high.\n","NLTK tool is also a best learning kit because the learning curve of Python(NLTK is written on this) is very fast. NLTK incorporated most of the NLP tasks, it's too elegant and easy to work with. For all these kind of reasons, NLTK became one of the popular libraries in the NLP community."]},{"cell_type":"code","metadata":{"id":"eZcZAgnAqwGa"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BuHd7t-qwGe"},"source":["# 1.3. Usage of NLP?\n","\n","In a real-world many more tools we use everyday, let's get a brief of some of the tools:\n","\n","<h3>1.Search Autocomplete</h3>\n","\n","It is another type of NLP that many people uses on a daily basis and have almost get what you expect when you are searching. This is thanks in large part to pioneers like Google, Google has been using these features in their search engines for years. This feature is also much helpful in companies website.\n","\n","   Search autocomplete will provide help to locate the correct information and answer their questions fastly.This helps to      cutdown the likelihood that they'll became disinterested and navigate away from the site.\n","   \n","<img src=\".\\Images\\4.png\">\n","\n","<h3>2.Search Autocorrect</h3>\n","\n","When we are typing something, we won't realize and make some mistakes while typing.If a search engine on a website won't catch those mistakes and instead show no results, then potential buyers might assume like you don't have the information or answer's they are looking for and may instead go to the competitor.\n","\n","   We seen these when we type something wrong and Google's search engine will autocorrect your result and give a correct information about the topic.\n","   \n","<img src=\".\\Images\\5.png\">\n","\n","<h3>3.Machine Translation</h3>\n","\n","Suppose you're in china and you don't know chinese and you have to ask some address to local people but they are conversing to you in chinese then at that time Machine translation is saviour for you. One of the famous machine translation tool made by google, it will give you probably correct results always.\n","\n","<img src=\".\\Images\\6.png\">\n","\n","<h3>4.Messenger Bots</h3>\n","\n","Facebook messenger is one of the best and latest ways to connect with customers for business purposes through a social media.NLP makes it possible to extend the functionality of these bots so that they are not just advertising a product or services, but can interact with their customers and provide them a unique experience.\n","\n","In 2015, Uber launched its Facebook messenger bot. This bot make a quick and easy for user to order their cars from the Facebook Messenger app.And it would be too useful for a customer to just type their address and the messenger bot will fetch your address and put it up in their pickup address.\n","\n","<img src=\".\\Images\\7.jpg\">"]},{"cell_type":"code","metadata":{"id":"q2ZiPD_NqwGg"},"source":[""],"execution_count":null,"outputs":[]}]}